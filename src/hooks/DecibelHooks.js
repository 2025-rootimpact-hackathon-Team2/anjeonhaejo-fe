import { useState, useEffect, useRef, use } from 'react';
import { useDispatch, useSelector } from 'react-redux';
import { updateDecibel, setIsRecording } from '@store/slices/decibelSlice';

const useDecibel = () => {
  const dispatch = useDispatch();
  const decibel = useSelector((state) => state.decibel.value);
  const isRecording = useSelector((state) => state.decibel.isRecording);
  const [isModalOpen, setIsModalOpen] = useState(false);
  const [isLoading, setIsLoading] = useState(false);

  const [audioUrl, setAudioUrl] = useState(null);

  const audioContextRef = useRef(null);
  const analyserRef = useRef(null);
  const dataArrayRef = useRef(null);
  const animationFrameId = useRef(null);
  const mediaRecorderRef = useRef(null);
  const mediaStreamRef = useRef(null);
  const audioChunksRef = useRef([]);
  const isCapturingRef = useRef(false);
  const isRecordingRef = useRef(false);

  const BUFFER_DURATION = 10; // ì „í›„ 10ì´ˆ ë…¹ìŒ
  const DECIBEL_THRESHOLD = 95; // ê¸°ì¤€ê°’ 90dB

  // ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™”
  const initAudioContext = async () => {
    if (!audioContextRef.current) {
      audioContextRef.current = new (window.AudioContext ||
        window.webkitAudioContext)();
      analyserRef.current = audioContextRef.current.createAnalyser();
      analyserRef.current.fftSize = 2048; // ë¶„ì„ í¬ê¸° ì¡°ì •
      dataArrayRef.current = new Uint8Array(
        analyserRef.current.frequencyBinCount
      );
    }
  };

  const calculateDecibel = () => {
    if (!analyserRef.current || !isRecordingRef.current) return;

    const dataArray = dataArrayRef.current;
    analyserRef.current.getByteFrequencyData(dataArray);

    let sum = 0;
    for (let i = 0; i < dataArray.length; i++) {
      sum += dataArray[i] * dataArray[i];
    }
    const rms = Math.sqrt(sum / dataArray.length);

    // ì‹¤ì œ RMS ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ë°ì‹œë²¨ ê³„ì‚°
    let decibelValue = 20 * Math.log10(rms) + 100;

    // í™”ë©´ì— í‘œì‹œë˜ëŠ” ë°ì‹œë²¨ ê°’ ë³´ì •
    const calibration = 45;
    const adjustedDecibel = decibelValue - calibration;

    const minDecibels = 0;
    const maxDecibels = 130;

    dispatch(
      updateDecibel(
        Math.min(maxDecibels, Math.max(minDecibels, adjustedDecibel))
      )
    );

    // ê¸°ì¤€ ë°ì‹œë²¨ì„ ë„˜ìœ¼ë©´ ë…¹ìŒ ì‹¤í–‰ (ë…¹ìŒ ë¡œì§ì€ ê·¸ëŒ€ë¡œ ìœ ì§€)
    if (adjustedDecibel > DECIBEL_THRESHOLD && !isCapturingRef.current) {
      isCapturingRef.current = true;
      console.log('ìµœì¢… ë°ì‹œë²¨ ê°’:', adjustedDecibel);
      console.log('90dB ì´ˆê³¼! ë…¹ìŒ ì‹œìž‘');

      setIsModalOpen(true);
      setIsLoading(true);

      captureAudio(adjustedDecibel).then(() => {
        stopRecording();
        console.log('ë…¹ìŒ ì¢…ë£Œ ë° ì„œë²„ ì „ì†¡ ì™„ë£Œ');
      });
    }
  };

  // ë°ì‹œë²¨ ì¸¡ì • ì‹œìž‘
  const startDecibelMonitoring = () => {
    const update = () => {
      calculateDecibel();
      animationFrameId.current = requestAnimationFrame(update);
    };
    animationFrameId.current = requestAnimationFrame(update);
  };

  // ë…¹ìŒ ì‹œìž‘ (í•œ ë²ˆë§Œ ì‹¤í–‰ë˜ë„ë¡ ë³´ì™„)
  const startRecording = async () => {
    if (isRecordingRef.current) return;
    isRecordingRef.current = true; // ë…¹ìŒ ì‹œìž‘ ìƒíƒœ ì„¤ì •

    try {
      await initAudioContext();
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      mediaStreamRef.current = stream;

      const source = audioContextRef.current.createMediaStreamSource(stream);
      source.connect(analyserRef.current);

      mediaRecorderRef.current = new MediaRecorder(stream);
      mediaRecorderRef.current.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);

          const maxChunks = Math.ceil(BUFFER_DURATION);
          if (audioChunksRef.current.length > maxChunks) {
            audioChunksRef.current.shift();
          }
        }
        console.log(audioChunksRef.current);
      };

      mediaRecorderRef.current.start(1000);
      dispatch(setIsRecording(true));
      startDecibelMonitoring();
    } catch (error) {
      console.error('ë…¹ìŒ ì‹œìž‘ ì‹¤íŒ¨:', error);
      isRecordingRef.current = false; // ì‹¤íŒ¨ ì‹œ ìƒíƒœ ì´ˆê¸°í™”
    }
  };

  // ë…¹ìŒ ì¤‘ì§€ (ìƒíƒœê°’ ì´ˆê¸°í™” ì¶”ê°€)
  const stopRecording = () => {
    if (mediaRecorderRef.current) {
      mediaRecorderRef.current.stop();
    }
    if (mediaStreamRef.current) {
      mediaStreamRef.current.getTracks().forEach((track) => track.stop());
    }
    if (animationFrameId.current) {
      cancelAnimationFrame(animationFrameId.current);
    }

    isRecordingRef.current = false;
    isCapturingRef.current = false;
    audioChunksRef.current = [];
    dispatch(setIsRecording(false));
    dispatch(updateDecibel(0));
  };

  // ë…¹ìŒ í›„ ì„œë²„ ì „ì†¡
  const captureAudio = async (adjustedDecibel) => {
    console.log('ðŸŽ¤ ë…¹ìŒ ì‹œìž‘: ë²„í¼ ìœ ì§€ ì¤‘...');
    await new Promise((resolve) => setTimeout(resolve, BUFFER_DURATION * 1000));

    if (audioChunksRef.current.length === 0) {
      console.warn('âš  ë…¹ìŒëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.');
      isCapturingRef.current = false;
      return;
    }

    const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
    console.log('ë…¹ìŒëœ íŒŒì¼ í¬ê¸°:', audioBlob.size);
    const url = URL.createObjectURL(audioBlob);
    console.log('ë…¹ìŒëœ íŒŒì¼ URL:', url);
    setAudioUrl(url);
    // Blobì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ í™•ì¸í•˜ëŠ” ì½”ë“œ
    const a = document.createElement('a');
    a.href = url;
    a.download = 'recorded_audio.webm';
    document.body.appendChild(a);
    a.click();
    document.body.removeChild(a);

    await sendToServer(audioBlob, adjustedDecibel);
    stopRecording(); // ì „ì†¡ í›„ ë…¹ìŒ ì™„ì „ížˆ ì¤‘ì§€
  };

  // ì„œë²„ë¡œ ì˜¤ë””ì˜¤ ë°ì´í„° ì „ì†¡
  const sendToServer = async (audioBlob, adjustedDecibel) => {
    console.log('ì„œë²„ë¡œ ì˜¤ë””ì˜¤ íŒŒì¼ ì „ì†¡ ì¤‘...');
    const formData = new FormData();
    formData.append('decibel', adjustedDecibel.toFixed(1));
    formData.append('workerZone', 1);
    formData.append('file', audioBlob, 'audio.webm');

    try {
      const response = await fetch('https://api.anjeons.com/audio/upload', {
        method: 'POST',
        body: formData,
      });

      if (!response.ok) throw new Error('ì„œë²„ ì „ì†¡ ì‹¤íŒ¨');
      console.log('ì˜¤ë””ì˜¤ ì „ì†¡ ì„±ê³µ');
      window.location.reload();
    } catch (error) {
      console.error('ì˜¤ë””ì˜¤ ì „ì†¡ ì˜¤ë¥˜:', error);
      window.location.reload();
      alert('ë¶„ì„í•œ ìŒì„±ì´ ìœ„í—˜ìœ¼ë¡œ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
    }
  };

  const handleConfirm = () => {
    setIsModalOpen(false);
  };

  const handleCancel = () => {
    setIsModalOpen(false);
    setIsLoading(false);
  };

  useEffect(() => {
    // setTimeout(() => {
    //   startRecording();
    // }, 1000);
    // startRecording();

    return () => {
      stopRecording();
      if (audioContextRef.current) {
        audioContextRef.current.close();
      }
    };
  }, []);

  return {
    decibel,
    isRecording,
    startRecording,
    stopRecording,
    isModalOpen,
    setIsModalOpen,
    handleConfirm,
    handleCancel,
    isLoading,
  };
};

export default useDecibel;
